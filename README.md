# Large Language Model 
This project is based on the GPT-3 architecture and is trained on a corpus of text data. GPT-3 was designed as a general-purpose language model, which means it can be used for a wide variety of natural language processing tasks, such as language translation, text summarization, and questioning tasks.
# Prerequisites
- Python
- TensorFlow
- Transformer library
# Installation
The easiest way to get it is by using pip.
- Python
- pip
- pip install virtualenvwrapper
- virtualenvwrapper (virtualenv or any other package manager you prefer)
# Training
A Corpus of text data was collected to trained this Model. The training was monitor and hyperparameters were adjusted 



