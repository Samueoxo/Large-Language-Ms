# Large Language Model 
This project is based on the GPT-3 architecture and is trained on a corpus of text data. GPT-3 was designed as a general-purpose language model, which means it can be used for a wide variety of natural language processing tasks, such as language translation, text summarization, and questioning tasks.
# Prerequisites
- Python
- TensorFlow
- Transformer library
# Installation
The easiest way to get it is by using pip
pip install virtualenvwrapper
In summary, you should have this packages installed in your system
- Python
- pip
- virtualenvwrapper (virtualenv or any other package manager you prefer)
# Training
-A Corpus of text data was collected to trained this Model.
-The training was monitor and hyperparameters were adjusted 


